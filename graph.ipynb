{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from tools import llm, custom_llm_with_tools\n",
    "\n",
    "from VectorDB import VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSIST_DIR = \"./chroma_langchain_db\"\n",
    "COLLECTION_NAME = \"movies_collection\"\n",
    "\n",
    "# Initialize vector database\n",
    "vector_db = VectorDB(model_name=\"BAAI/bge-base-en-v1.5\", batch_size=32)\n",
    "init_result = vector_db.initialize_vector_store(PERSIST_DIR, COLLECTION_NAME)\n",
    "\n",
    "vector_store = vector_db.vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848511af",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_prompt = (\n",
    "    \"You are a movie recommendation / finding assistant, your job is to help users find movies based on their preferences.\"\n",
    "    \"You will start by reading the user's query and then searching for relevant movies in the database.\"\n",
    "    \"Then you will use the available context to provide a personalized recommendation of a movie title:\" \\\n",
    "    \"- Identify the main 3 genres of the movie from the context\"\n",
    "    \"- Identify the the release year, director, and main actors of the movie from the context\"\n",
    "    \"- Identify the main themes and plotline of the movie from the context\"\n",
    "    \"When generating the final response, make sure to include all relevant information in the following order:\"\n",
    "    \"1 - Title:\"\n",
    "    \"2 - Genres:\"\n",
    "    \"3 - Release Year, Director, and Main Actors:\"\n",
    "    \"4 - Themes and Plotline:\"\n",
    "    \"Query:\\n{question}\"\n",
    "    \"Context:\\n{context}\\n\"\n",
    ")\n",
    "\n",
    "GENERATOR_PROMPT = PromptTemplate.from_template(generator_prompt)\n",
    "\n",
    "class State(MessagesState):\n",
    "    context: List[Document]\n",
    "\n",
    "\n",
    "class MovieRecommendationWithSources(TypedDict):\n",
    "    \"\"\"A movie recommendation with detailed information and sources.\"\"\"\n",
    "    \n",
    "    movie_title: str\n",
    "    genres: Annotated[\n",
    "        List[str], \n",
    "        \"Main 3 genres of the recommended movie\"\n",
    "    ]\n",
    "    release_year: Annotated[\n",
    "        int,\n",
    "        \"Year the movie was released\"\n",
    "    ]\n",
    "    director: Annotated[\n",
    "        str,\n",
    "        \"Director of the movie\"\n",
    "    ]\n",
    "    main_actors: Annotated[\n",
    "        List[str],\n",
    "        \"List of main actors in the movie\"\n",
    "    ]\n",
    "    themes_and_plot: Annotated[\n",
    "        str,\n",
    "        \"Brief description of main themes and plotline\"\n",
    "    ]\n",
    "    recommendation_reason: Annotated[\n",
    "        str,\n",
    "        \"Detailed explanation of why this movie matches the user's preferences\"\n",
    "    ]\n",
    "    sources: Annotated[\n",
    "        List[str],\n",
    "        \"List of source documents/databases used to gather this movie information\"\n",
    "    ]\n",
    "\n",
    "def query_or_respond(state: State):\n",
    "    \"\"\"Generate tool call for movie retrieval or respond directly.\"\"\"\n",
    "    \n",
    "    # Add system message to encourage tool usage for movie queries\n",
    "    system_message = SystemMessage(content=(\n",
    "        \"You are a movie recommendation assistant. When users ask about movies, \"\n",
    "        \"you should use the retrieve tool to search the movie database \"\n",
    "        \"before providing recommendations. Only recommend movies found in the database.\"\n",
    "    ))\n",
    "    \n",
    "    # Combine system message with conversation history\n",
    "    messages_with_system = [system_message] + state[\"messages\"]\n",
    "    \n",
    "    # Bind tools to the LLM\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(messages_with_system)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    # Increase k to get more movies when user asks for multiple recommendations\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=6)  # Increased from 2 to 6\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate structured movie recommendation with sources.\"\"\"\n",
    "    \n",
    "    # Get the most recent tool messages (movie retrieval results)\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]  # Reverse to get correct order\n",
    "    \n",
    "    # Format movie information for the context\n",
    "    movies_content = \"\\n\\n\".join(msg.content for msg in tool_messages)\n",
    "    \n",
    "    # Get the most recent user question\n",
    "    user_question = \"\"\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"human\":\n",
    "            user_question = message.content\n",
    "            break\n",
    "    \n",
    "    # Enhanced prompt for better recommendations with explicit field requirements\n",
    "    enhanced_prompt = f\"\"\"You are a movie recommendation assistant. Based on the user's query and the provided movie database context, provide a detailed movie recommendation.\n",
    "\n",
    "User Query: {user_question}\n",
    "\n",
    "Available Movies from Database:\n",
    "{movies_content}\n",
    "\n",
    "IMPORTANT: You must fill out ALL fields in your response:\n",
    "- movie_title: The exact title of the movie\n",
    "- genres: List the main 3 genres (e.g., [\"Science Fiction\", \"Thriller\", \"Drama\"])\n",
    "- release_year: The year as a number\n",
    "- director: Full name of the director\n",
    "- main_actors: List of main actor names (e.g., [\"Harrison Ford\", \"Rutger Hauer\", \"Sean Young\"])\n",
    "- themes_and_plot: Detailed description of the plot and main themes\n",
    "- recommendation_reason: Explain why this movie matches the user's request\n",
    "- sources: List of sources used (e.g., [\"Movie Database\", \"IMDb\"])\n",
    "\n",
    "Only recommend ONE movie that is mentioned in the database context above. Extract all information from the provided context.\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Use structured output for movie recommendations\n",
    "        structured_llm = llm.with_structured_output(MovieRecommendationWithSources)\n",
    "        response = structured_llm.invoke(enhanced_prompt)\n",
    "        \n",
    "        # Debug: print what we got\n",
    "        print(\"DEBUG - Structured response:\", response)\n",
    "        \n",
    "        # Safely extract fields with defaults\n",
    "        movie_title = response.get('movie_title', 'Unknown Movie')\n",
    "        release_year = response.get('release_year', 'Unknown')\n",
    "        director = response.get('director', 'Unknown Director')\n",
    "        genres = response.get('genres', ['Unknown Genre'])\n",
    "        main_actors = response.get('main_actors', ['Unknown Actor'])\n",
    "        themes_and_plot = response.get('themes_and_plot', 'Plot information not available.')\n",
    "        recommendation_reason = response.get('recommendation_reason', 'This movie was found in the database.')\n",
    "        sources = response.get('sources', ['Movie Database'])\n",
    "        \n",
    "        # Ensure genres and main_actors are lists\n",
    "        if isinstance(genres, str):\n",
    "            genres = [genres]\n",
    "        if isinstance(main_actors, str):\n",
    "            main_actors = [main_actors]\n",
    "        \n",
    "        # Create verbose response\n",
    "        verbose_response = f\"\"\"Based on your request, here's my recommendation from the database:\n",
    "\n",
    "ðŸŽ¬ **{movie_title}** ({release_year})\n",
    "\n",
    "**Director:** {director}\n",
    "**Genres:** {', '.join(genres)}\n",
    "**Cast:** {', '.join(main_actors)}\n",
    "\n",
    "**Plot & Themes:**\n",
    "{themes_and_plot}\n",
    "\n",
    "**Why I recommend this movie:**\n",
    "{recommendation_reason}\n",
    "\n",
    "**Sources:** {', '.join(sources)}\"\"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in structured generation: {e}\")\n",
    "        # Fallback to simple response\n",
    "        verbose_response = f\"\"\"Based on your request and the available database entries, I found relevant movies but encountered an issue with structured formatting. \n",
    "\n",
    "Here's what I found in the database:\n",
    "{movies_content[:500]}...\n",
    "\n",
    "Please try your request again or be more specific about what type of movie you're looking for.\"\"\"\n",
    "    \n",
    "    # Extract context from tool message artifacts for state tracking\n",
    "    context = []\n",
    "    for tool_message in tool_messages:\n",
    "        if hasattr(tool_message, 'artifact') and tool_message.artifact:\n",
    "            context.extend(tool_message.artifact)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"assistant\", \"content\": response}], \n",
    "        \"context\": context\n",
    "    }\n",
    "\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def chatbot(state: State):\n",
    "#    return {\"messages\": [llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph_builder = StateGraph(State)\n",
    "\n",
    "#graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "#graph_builder.add_edge(START, \"chatbot\")\n",
    "#graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "    \n",
    "# Add nodes\n",
    "graph_builder.add_node(\"query_or_respond\", query_or_respond)\n",
    "graph_builder.add_node(\"tools\", tools)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "\n",
    "# Set entry point\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "\n",
    "# Add conditional edges\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "\n",
    "# Add regular edges\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f5d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Recommend 3 good sci-fi movie from the 1980s.\"}]\n",
    "})\n",
    "\n",
    "# Access the final response\n",
    "final_message = result[\"messages\"][-1]\n",
    "print(final_message.content)\n",
    "\n",
    "# Access the retrieved context (movies that were found)\n",
    "retrieved_movies = result[\"context\"]\n",
    "print(f\"Found {len(retrieved_movies)} movies in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9788f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53268689",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98733a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any tool calls were made\n",
    "for msg in result[\"messages\"]:\n",
    "    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "        print(f\"Tool calls made: {[tc['name'] for tc in msg.tool_calls]}\")\n",
    "    else:\n",
    "        print(f\"Message type {msg.type}: No tool calls\")\n",
    "\n",
    "print(f\"Context available: {'context' in result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42918cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = retrieve(\"1980s sci-fi movies\")\n",
    "print(\"Tool result:\", result)\n",
    "print(\"Type:\", type(result))\n",
    "\n",
    "# If it returns a tuple (content, artifacts)\n",
    "if isinstance(result, tuple):\n",
    "    content, artifacts = result\n",
    "    print(\"Content:\", content)\n",
    "    print(\"Artifacts count:\", len(artifacts) if artifacts else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c38f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([retrieve])\n",
    "\n",
    "# Create a more explicit message that should trigger tool usage\n",
    "test_messages = [\n",
    "    SystemMessage(content=\"You must use the retrieve tool to search for movies. Do not answer without using the tool.\"),\n",
    "    HumanMessage(content=\"Find me 1980s sci-fi movies from the database\")\n",
    "]\n",
    "\n",
    "response = llm_with_tools.invoke(test_messages)\n",
    "print(\"Response type:\", type(response))\n",
    "print(\"Has tool calls:\", hasattr(response, 'tool_calls') and bool(response.tool_calls))\n",
    "if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "    print(\"Tool calls:\", response.tool_calls)\n",
    "else:\n",
    "    print(\"Response content:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21868ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LLM model:\", type(llm))\n",
    "print(\"LLM attributes:\", dir(llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    print(\"Tool binding successful\")\n",
    "    \n",
    "    # Check if the model has tool calling attributes\n",
    "    print(\"Model attributes:\", [attr for attr in dir(llm) if 'tool' in attr.lower()])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Tool binding failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e35decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what bind_tools actually creates\n",
    "llm_with_tools = llm.bind_tools([retrieve])\n",
    "print(\"LLM with tools type:\", type(llm_with_tools))\n",
    "print(\"LLM with tools attributes:\", [attr for attr in dir(llm_with_tools) if not attr.startswith('_')])\n",
    "\n",
    "# Check if tools are properly bound\n",
    "if hasattr(llm_with_tools, 'bound_tools'):\n",
    "    print(\"Bound tools:\", llm_with_tools.bound_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf0ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messages = [\n",
    "    SystemMessage(content=\"You have access to a tool called 'retrieve'. Use it to search for movies.\"),\n",
    "    HumanMessage(content=\"Call retrieve with query '1980s sci-fi'\")\n",
    "]\n",
    "\n",
    "response = llm_with_tools.invoke(test_messages)\n",
    "print(\"Explicit format - Tool calls:\", getattr(response, 'tool_calls', None))\n",
    "\n",
    "# Test 2: JSON-like instruction\n",
    "test_messages2 = [\n",
    "    HumanMessage(content=\"Please use the retrieve function to search for '1980s sci-fi movies'. Call: retrieve(query='1980s sci-fi movies')\")\n",
    "]\n",
    "\n",
    "response2 = llm_with_tools.invoke(test_messages2)\n",
    "print(\"JSON format - Tool calls:\", getattr(response2, 'tool_calls', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "print(\"Loading model and tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Check if your model has specific tool calling requirements\n",
    "print(\"Model config:\", llm.llm.pipeline.model.config)\n",
    "print(\"Tokenizer chat template:\", tokenizer.chat_template if hasattr(tokenizer, 'chat_template') else \"No chat template\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3bf94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    llm_forced = llm.bind_tools([retrieve], tool_choice=\"any\")\n",
    "    response = llm_forced.invoke([HumanMessage(content=\"Find 1980s sci-fi movies\")])\n",
    "    print(\"Forced tool choice - Tool calls:\", getattr(response, 'tool_calls', None))\n",
    "except Exception as e:\n",
    "    print(f\"Tool choice failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_message = \"\"\"Given the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.\n",
    "\n",
    "Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}. Do not use variables.\n",
    "\n",
    "{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"retrieve\",\n",
    "        \"description\": \"Retrieve movie information related to a user's preferences and query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Search query for movies\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "Find me sci-fi movies from the 1980s.\"\"\"\n",
    "\n",
    "response = llm.invoke([HumanMessage(content=test_message)])\n",
    "print(\"Response:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ca00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Test basic tool calling\n",
    "llm_with_tools = llm.bind_tools([retrieve])\n",
    "\n",
    "test_messages = [\n",
    "    SystemMessage(content=\"You are an assistant that must use tools when available. Use the retrieve_movies tool when asked about movies.\"),\n",
    "    HumanMessage(content=\"Use the retrieve_movies tool to find sci-fi movies from the 1980s\")\n",
    "]\n",
    "\n",
    "response = llm_with_tools.invoke(test_messages)\n",
    "print(\"Response type:\", type(response))\n",
    "print(\"Response content:\", response.content)\n",
    "print(\"Has tool calls:\", hasattr(response, 'tool_calls'))\n",
    "print(\"Tool calls:\", getattr(response, 'tool_calls', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb3ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tool name:\", retrieve.name)\n",
    "print(\"Tool description:\", retrieve.description)\n",
    "print(\"Tool args:\", retrieve.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    llm_forced = llm.bind_tools([retrieve], tool_choice=\"any\")\n",
    "    response = llm_forced.invoke([HumanMessage(content=\"Find 1980s sci-fi movies\")])\n",
    "    print(\"Forced tool choice - Tool calls:\", getattr(response, 'tool_calls', None))\n",
    "except Exception as e:\n",
    "    print(f\"Tool choice failed: {e}\")\n",
    "\n",
    "# Try with a very explicit message\n",
    "explicit_msg = HumanMessage(content=\"I need you to call the retrieve function with the query '1980s sci-fi movies'. Please use the available tool.\")\n",
    "response = llm_with_tools.invoke([explicit_msg])\n",
    "print(\"Explicit message - Tool calls:\", getattr(response, 'tool_calls', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a966da64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragflix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
