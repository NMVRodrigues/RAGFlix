{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from tools import llm\n",
    "\n",
    "from VectorDB import VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSIST_DIR = \"./chroma_langchain_db\"\n",
    "COLLECTION_NAME = \"movies_collection\"\n",
    "\n",
    "# Initialize vector database\n",
    "vector_db = VectorDB(model_name=\"BAAI/bge-base-en-v1.5\", batch_size=32)\n",
    "init_result = vector_db.initialize_vector_store(PERSIST_DIR, COLLECTION_NAME)\n",
    "\n",
    "vector_store = vector_db.vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848511af",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_prompt = (\n",
    "    \"You are a movie recommendation / finding assistant, your job is to help users find movies based on their preferences.\"\n",
    "    \"You will start by reading the user's query and then searching for relevant movies in the database.\"\n",
    "    \"Then you will use the available context to provide a personalized recommendation of a movie title:\" \\\n",
    "    \"- Identify the main 3 genres of the movie from the context\"\n",
    "    \"- Identify the the release year, director, and main actors of the movie from the context\"\n",
    "    \"- Identify the main themes and plotline of the movie from the context\"\n",
    "    \"When generating the final response, make sure to include all relevant information in the following order:\"\n",
    "    \"1 - Title:\"\n",
    "    \"2 - Genres:\"\n",
    "    \"3 - Release Year, Director, and Main Actors:\"\n",
    "    \"4 - Themes and Plotline:\"\n",
    "    \"Query:\\n{question}\"\n",
    "    \"Context:\\n{context}\\n\"\n",
    ")\n",
    "\n",
    "GENERATOR_PROMPT = PromptTemplate.from_template(generator_prompt)\n",
    "\n",
    "class State(MessagesState):\n",
    "    context: List[Document]\n",
    "\n",
    "\n",
    "class MovieRecommendationWithSources(TypedDict):\n",
    "    \"\"\"A movie recommendation with detailed information and sources.\"\"\"\n",
    "    \n",
    "    movie_title: str\n",
    "    genres: Annotated[\n",
    "        List[str], \n",
    "        \"Main 3 genres of the recommended movie\"\n",
    "    ]\n",
    "    release_year: Annotated[\n",
    "        int,\n",
    "        \"Year the movie was released\"\n",
    "    ]\n",
    "    director: Annotated[\n",
    "        str,\n",
    "        \"Director of the movie\"\n",
    "    ]\n",
    "    main_actors: Annotated[\n",
    "        List[str],\n",
    "        \"List of main actors in the movie\"\n",
    "    ]\n",
    "    themes_and_plot: Annotated[\n",
    "        str,\n",
    "        \"Brief description of main themes and plotline\"\n",
    "    ]\n",
    "    recommendation_reason: Annotated[\n",
    "        str,\n",
    "        \"Detailed explanation of why this movie matches the user's preferences\"\n",
    "    ]\n",
    "    sources: Annotated[\n",
    "        List[str],\n",
    "        \"List of source documents/databases used to gather this movie information\"\n",
    "    ]\n",
    "\n",
    "def query_or_respond(state: State):\n",
    "    \"\"\"Generate tool call for movie retrieval or respond directly.\"\"\"\n",
    "    \n",
    "    # Add system message to encourage tool usage for movie queries\n",
    "    system_message = SystemMessage(content=(\n",
    "        \"You are a movie recommendation assistant. When users ask about movies, \"\n",
    "        \"you should use the retrieve tool to search the movie database \"\n",
    "        \"before providing recommendations. Only recommend movies found in the database.\"\n",
    "    ))\n",
    "    \n",
    "    # Combine system message with conversation history\n",
    "    messages_with_system = [system_message] + state[\"messages\"]\n",
    "    \n",
    "    # Bind tools to the LLM\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(messages_with_system)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    # Increase k to get more movies when user asks for multiple recommendations\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=6)  # Increased from 2 to 6\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate movie recommendation response.\"\"\"\n",
    "    \n",
    "    # Get the most recent tool messages (movie retrieval results)\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]  # Reverse to get correct order\n",
    "    \n",
    "    # Format movie information for the context\n",
    "    movies_content = \"\\n\\n\".join(msg.content for msg in tool_messages)\n",
    "    \n",
    "    # Get the most recent user question\n",
    "    user_question = \"\"\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"human\":\n",
    "            user_question = message.content\n",
    "            break\n",
    "    \n",
    "    # Simplified generation prompt\n",
    "    generation_prompt = f\"\"\"You are a movie recommendation assistant. Based on the user's query and the provided movie database context, provide detailed movie recommendations.\n",
    "\n",
    "User Query: {user_question}\n",
    "\n",
    "Available Movies from Database:\n",
    "{movies_content}\n",
    "\n",
    "Instructions:\n",
    "- Recommend movies that best match the user's preferences\n",
    "- If they ask for multiple movies, recommend multiple movies from the database\n",
    "- Include relevant details like title, year, director, cast, genres, and plot\n",
    "- Explain why each movie matches their request\n",
    "- Only recommend movies that appear in the database context above\n",
    "- Format your response clearly and engagingly\n",
    "\n",
    "Provide your recommendations now:\"\"\"\n",
    "\n",
    "    # Generate response using the LLM directly\n",
    "    response = llm.invoke([HumanMessage(content=generation_prompt)])\n",
    "    \n",
    "    # Extract context from tool message artifacts for state tracking\n",
    "    context = []\n",
    "    for tool_message in tool_messages:\n",
    "        if hasattr(tool_message, 'artifact') and tool_message.artifact:\n",
    "            context.extend(tool_message.artifact)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response], \n",
    "        \"context\": context\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def chatbot(state: State):\n",
    "#    return {\"messages\": [llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph_builder = StateGraph(State)\n",
    "\n",
    "#graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "#graph_builder.add_edge(START, \"chatbot\")\n",
    "#graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "    \n",
    "# Add nodes\n",
    "graph_builder.add_node(\"query_or_respond\", query_or_respond)\n",
    "graph_builder.add_node(\"tools\", tools)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "\n",
    "# Set entry point\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "\n",
    "# Add conditional edges\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "\n",
    "# Add regular edges\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f5d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Recommend 3 movies about space exploration, containing aliens. Idealy they should be horror sci-fi movies.\"}]\n",
    "})\n",
    "\n",
    "# Access the final response\n",
    "final_message = result[\"messages\"][-1]\n",
    "print(final_message.content)\n",
    "\n",
    "# Access the retrieved context (movies that were found)\n",
    "retrieved_movies = result[\"context\"]\n",
    "print(f\"Found {len(retrieved_movies)} movies in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a966da64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragflix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
